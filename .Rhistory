n
n
n
myfunction()
"R_coursera.R"
ls()
ls()
myfunction()
second(4)
"R_coursera.R"
ls()
myfunction()
"R_coursera.R"
source("R.coursera.R")
source("R_coursera.R")
q()
swirl
swirl()
library(swirl)
swirl()
5+7
x <- 5+7
x
y <- x-3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z*2+100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1:4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 19)
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z*2+1000
my_div
getwd()
ls()
x <- 9
ls()
list.files()
?list.files
args()
args(list.files())
args(list.files)
old.dir <- args(list.files)
old.dir <- getwd()
dir.create(test.dir)
dir.create(testdir)
testdir <- dir.create
dir.create("testdir")
setwd("testdir)
setwd("testdir")
setwd("testdir")
file.create("mytest.R")
list.files()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
file.path(folder1, folder2)
file.path("folder1", "folder2")
?dir.create
file.path(dir.create("testdir2", "testdir3"))
dir.create(file.path('testdir2', 'testdir3'), recursive = TRUE)
setwd(old.dir)
1:20
pi:10
15:1
:
?`:`
seq(1,20)
seq(0, 10, by=0.5)
seq(5, 10, length=30)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
q()
install.packages("shiny")
library(shiny)
runExample("01_hello")
shiny::runApp('GitHub/cytosel')
colnames(colData(sce()))
runApp('GitHub/cytosel')
runApp('GitHub/cytosel')
## TODO: support multiple columns
column
print(class(column))
print(column)
runApp('GitHub/cytosel')
runApp()
runApp('GitHub/cytosel')
setwd("~/GitHub/cytosel")
}
train_nb <- function(x,y, cell_types) {
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)
metrics <- lapply(flds, function(test_idx) {
fit <- naive_bayes(x[-test_idx,], y[-test_idx])
p <- predict(fit, newdata = x[test_idx,])
overall <- bal_accuracy_vec(y[test_idx], p)
scores <- sapply(cell_types, function(ct) {
ppv_vec(factor(y[test_idx] == ct, levels=c("TRUE", "FALSE")),
factor(p == ct, levels = c("TRUE", "FALSE")))
})
tibble(
what = c("Overall", cell_types),
score=c(overall, scores)
)
}) %>% bind_rows()
metrics
}
create_heatmap <- function(sce, markers, column, normalization, pref_assay = "logcounts") {
normalization <- match.arg(normalization, c("Expression", "z-score"))
## TODO: support multiple columns -- currently takes first by default
column <- column[1]
mat <- scuttle::summarizeAssayByGroup(
sce,
id = colData(sce)[[column]],
subset.row = markers$top_markers,
statistics = 'mean',
assay.type = pref_assay
)
mat <- (assay(mat, 'mean'))
legend <- "Mean\nexpression"
if(normalization == "z-score") {
mat <- t(scale(t(mat)))
legend <- "z-score\nexpression"
}
# top_annot <- HeatmapAnnotation()
expression_mat <- Heatmap(mat,
col = viridis(100),
name="Expresison")
cor_mat <- Heatmap(cor(t(mat)),
name="Correlation")
expression_mat + cor_mat
}
round3 <- function(x) format(round(x, 1), nsmall = 3)
## TODO: support multiple columns
column <- column[1]
runApp()
runApp()
runApp()
runApp()
runApp()
get_scores <- function(sce, column, mrkrs, max_cells = 5000, pref_assay = "logcounts") {
## TODO: support more than one column
# column <- column[1]
max_cells <- min(ncol(sce), max_cells)
sce_tr <- sce[mrkrs, sample(ncol(sce), max_cells, replace=FALSE)]
scores <- list()
for(column in columns) {
scores[[column]] <- get_scores_one_column(sce_tr, column, mrkrs, max_cells, pref_assay)
}
scores
}
get_scores_one_column <- function(sce_tr, column, mrkrs, max_cells = 5000, pref_assay = "logcounts") {
## TODO: support more than one column
column <- column[1]
x <- t(assay(sce_tr, pref_assay))
x <- as.matrix(x)
y <- factor(colData(sce_tr)[[ column ]])
cell_types <- sort(unique(colData(sce_tr)[[column]]))
train_nb(x,y, cell_types)
}
train_nb <- function(x,y, cell_types) {
flds <- createFolds(y, k = 10, list = TRUE, returnTrain = FALSE)
metrics <- lapply(flds, function(test_idx) {
fit <- naive_bayes(x[-test_idx,], y[-test_idx])
p <- predict(fit, newdata = x[test_idx,])
overall <- bal_accuracy_vec(y[test_idx], p)
scores <- sapply(cell_types, function(ct) {
ppv_vec(factor(y[test_idx] == ct, levels=c("TRUE", "FALSE")),
factor(p == ct, levels = c("TRUE", "FALSE")))
})
tibble(
what = c("Overall", cell_types),
score=c(overall, scores)
)
}) %>% bind_rows()
metrics
}
create_heatmap <- function(sce, markers, column, normalization, pref_assay = "logcounts") {
normalization <- match.arg(normalization, c("Expression", "z-score"))
## TODO: support multiple columns -- currently takes first by default
column <- column[1]
mat <- scuttle::summarizeAssayByGroup(
sce,
id = colData(sce)[[column]],
subset.row = markers$top_markers,
statistics = 'mean',
assay.type = pref_assay
)
mat <- (assay(mat, 'mean'))
legend <- "Mean\nexpression"
if(normalization == "z-score") {
mat <- t(scale(t(mat)))
legend <- "z-score\nexpression"
}
# top_annot <- HeatmapAnnotation()
expression_mat <- Heatmap(mat,
col = viridis(100),
name="Expresison")
cor_mat <- Heatmap(cor(t(mat)),
name="Correlation")
expression_mat + cor_mat
}
round3 <- function(x) format(round(x, 1), nsmall = 3)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
